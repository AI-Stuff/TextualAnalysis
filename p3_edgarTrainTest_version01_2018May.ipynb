{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program randomly selects a subset of Item7 filings from a directory,\n",
    "then randomly selects a subset of sentences from those filings\n",
    "that will be hand-labelled.\n",
    "Some of those hand-labelled sentences will be used for training and some for testing.\n",
    "\n",
    "\n",
    "Murat Aydogdu \n",
    "May 5, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, csv, time, nltk\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/murataydogdu/Desktop/TextualAnalysis/Version1_2018June_Programs\r\n"
     ]
    }
   ],
   "source": [
    "# This is the root directory under which TXT directory resides\n",
    "os.chdir('/Users/murataydogdu/Desktop/TextualAnalysis/Version1_2018June_Programs')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the names of all the text files in the directory.\n",
    "# Normally, there should be nothing else here\n",
    "txtfiles = []\n",
    "for file in os.listdir(\"TXT\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        txtfiles.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "805\n"
     ]
    }
   ],
   "source": [
    "# Randomly select 20% of the filings\n",
    "trtest_files = random.sample(txtfiles, int(len(txtfiles)*0.20))\n",
    "print len(trtest_files)#, trtest_files       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', '(', 'not', ')', 'sure', 'this', 'is', \"n't\", 'right', '.']\n"
     ]
    }
   ],
   "source": [
    "time.ctime()\n",
    "print nltk.word_tokenize(\"I am (not) sure this isn't right.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/murataydogdu/Desktop/TextualAnalysis/trtest_10K.csv', 'wt') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # The file does not need a header. Its output will be:\n",
    "    # 5 (null sentiment code), trfile, sent_cnt, sent_ind, word_cnt, full_sent separated by _*_\n",
    "    os.chdir('/Users/murataydogdu/Desktop/TextualAnalysis/Version1_2018June_Programs/TXT')\n",
    "    for trfile in trtest_files:\n",
    "        # read the text file first\n",
    "        with open(trfile, 'rb') as f:\n",
    "            reader = csv.reader(f)\n",
    "            sentences = list(reader)\n",
    "        # total size of the document: sum of number of words in each line\n",
    "        doclength = 0\n",
    "        for sentence in sentences:\n",
    "            # This is for when the sentence has commas in it. \n",
    "            # In that case the sentence will be split.\n",
    "            full_sent = \",\".join([str(i) for i in sentence])\n",
    "            full_sent = nltk.word_tokenize(full_sent.decode(\"utf8\"))\n",
    "            # This will count punctuation marks as words.\n",
    "            #print (full_sent, len(full_sent))\n",
    "            doclength += len(full_sent)\n",
    "        print trfile, doclength   \n",
    "        sent_cnt = len(sentences) # Number of sentences in a document\n",
    "        if doclength >= 2500:     # LM (2011) has 2000 words as treshold.\n",
    "                                  # I am counting non-word tokens also.\n",
    "            # Randomly select 5% of sentences and record the indices of these sentences\n",
    "            sent_indices = random.sample(range(sent_cnt),int(sent_cnt*0.05))\n",
    "\n",
    "            for sent_ind in sent_indices:\n",
    "                sent = sentences[sent_ind]\n",
    "                # Sentences are split if there's a comma: put them back together\n",
    "                full_sent = \",\".join([str(i) for i in sent]) \n",
    "                # Number of words in the sentence\n",
    "                word_cnt = len(nltk.word_tokenize(full_sent.decode(\"utf8\")))\n",
    "                if (word_cnt <= 50  and word_cnt >= 10):\n",
    "                    # This is a safety measure: \n",
    "                    # a very long sentence can be a sign of incorrect parsing \n",
    "                    # (more than one sentence, ...)\n",
    "                    # Short sentences can be headings, ToC, ...\n",
    "                    # Note, we are counting tokens not words.\n",
    "                    #print trfile, sent_cnt, sent_ind, word_cnt, full_sent\n",
    "                    line = '5 _*_ '+ trfile + ' _*_ ' + \"{:04}\".format(sent_cnt) + ' _*_ ' + \"{:04}\".format(sent_ind) + ' _*_ ' + \"{:04}\".format(word_cnt) + ' _*_ ' + full_sent \n",
    "                    print line\n",
    "                    writer.writerow([line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reopen the train/test file and shuffle sentences\n",
    "with open('/Users/murataydogdu/Desktop/TextualAnalysis/Version1_2018June_Programs/trtest_10K.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    sentences = list(reader)\n",
    "print (len(sentences), type(sentences))   \n",
    "\n",
    "new_sentences = random.sample(sentences, len(sentences)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the shuffled sentences in a new file\n",
    "with open('/Users/murataydogdu/Desktop/TextualAnalysis/Version1_2018June_Programs/new_trtest_10K.csv', 'wt') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for sentence in new_sentences:\n",
    "        print sentence\n",
    "        writer.writerow(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
